{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a0deca-3712-4093-9280-f396468a300c",
   "metadata": {},
   "source": [
    "# Rayleigh-Gauss-Newton optimization: implementing the necessary elements\n",
    "\n",
    "In this notebook, we look to implement using NetKet the Rayleigh-Gauss-Newton optimization presented in the paper of Robert J. Webber and Michael Lindsey.\n",
    "\n",
    "Recall the following equation:\n",
    "$$\n",
    "\\Delta \\vec{\\theta} = P^{-1} \\vec{F}.\n",
    "$$\n",
    "For SR, we went up to first order in our expansion. If we go to second order, we retrieve the Rayleigh-Gauss-Newton method:\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "\\mathrm{Method} & \\mathrm{Preconditionner \\,} P\\\\\n",
    "\\hline \n",
    "\\mathrm{Gradient \\, descent} & \\epsilon^{-1} I \\\\\n",
    "\\mathrm{Natural \\, gradient \\, descent} & \\epsilon^{-1}(S + \\eta I) \\\\\n",
    "\\mathrm{Rayleigh-Gauss-Newton} & H + \\epsilon^{-1}(S + \\eta I) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$H$ is the Hessian. However, computing the Hessian can be expensive, and thus we approximate it by: \n",
    "$$\n",
    "\\hat{H_{ij}} = \\mathrm{Cov}_{\\hat{\\rho}}[\\nu_i(\\sigma), E_{L,j}(\\sigma)] - \\hat{g}_i \\mathbb{E}_{\\hat{\\rho}}[\\nu_j (\\sigma)] - \\hat{\\mathcal{E}} \\hat{S_{ij}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\hat{\\mathcal{E}} = \\mathbb{E}_{\\hat{\\rho}}[E_L(\\sigma)]\n",
    "$$\n",
    "$$\n",
    "\\vec{F} = \\hat{g}_i = \\mathrm{Cov}_{\\hat{\\rho}}[\\nu_i(\\sigma), E_L(\\sigma)] = <(\\nu_i(\\sigma) - <\\nu_i(\\sigma)>) E_L(\\sigma)> = < \\left( \\frac{\\partial_{\\theta_i} \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}} - <\\frac{\\partial_{\\theta_i} \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}}> \\right) \\frac{H \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}}> = < \\frac{\\partial_{\\theta_i} \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}} \\left( \\frac{H \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}} - <\\frac{H \\braket{\\sigma|\\psi}}{\\braket{\\sigma|\\psi}}> \\right)>\n",
    "$$\n",
    "$$\n",
    "\\hat{S}_{ij} = \\mathrm{Cov}_{\\hat{\\rho}}[\\nu_i(\\sigma), \\nu_j(\\sigma)]\n",
    "$$\n",
    "\n",
    "Let us start implementing everything from scratch. We first import the necessary libraries, define the system and the Hamiltonian (that we will take to be $H = \\sum_{i = 1}^L S_i^z S_{i + 1}^z + \\Delta \\sum_{i = 1}^L \\left( S_i^x S_{i + 1}^x + S_i^y S_{i + 1}^y\\right)$ with $\\Delta = -1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb01cc92-7fec-4360-a6fa-fb28cd4c3da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriceconstantinmatar/uv-env/nk/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import netket library\n",
    "import netket as nk\n",
    "\n",
    "# Import Json, this will be needed to load log files\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "\n",
    "# jax and jax.numpy\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Flax is a framework to define models using jaxxx\n",
    "import flax\n",
    "# we refer to `flax.linen` as `nn`. It's a repository of \n",
    "# layers, initializers and nonlinear functions.\n",
    "import flax.linen as nn\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352052d8-d627-4763-b742-fdff5353bf11",
   "metadata": {},
   "source": [
    "We first define the system, the model and the Hamiltonian, which we will take to be $H = \\sum_{i = 1}^L S_i^z S_{i + 1}^z + \\Delta \\sum_{i = 1}^L \\left( S_i^x S_{i + 1}^x + S_i^y S_{i + 1}^y\\right)$. We will take $\\Delta = -1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d4ae0a-83be-4756-a053-94ec62ef1db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriceconstantinmatar/uv-env/nk/.venv/lib/python3.12/site-packages/netket/vqs/mc/mc_state/state.py:276: UserWarning: n_samples=300 (300 per device/MPI rank) does not divide n_chains=16, increased to 304 (304 per device/MPI rank)\n",
      "  self.n_samples = n_samples\n"
     ]
    }
   ],
   "source": [
    "L = 10\n",
    "\n",
    "# Define a 1d chain\n",
    "g = nk.graph.Hypercube(length=L, n_dim=1, pbc=True)\n",
    "    \n",
    "# Define the Hilbert space based on this graph\n",
    "# We impose to have a fixed total magnetization of zero \n",
    "hi = nk.hilbert.Spin(s=1/2, N=g.n_nodes)\n",
    "# Initialize the model\n",
    "model_RBM = nk.models.RBM(param_dtype = complex)\n",
    "\n",
    "# Define the local sampler on the Hilbert space\n",
    "sampler = nk.sampler.MetropolisLocal(hi)\n",
    "\n",
    "# Create the variational state\n",
    "vstate = nk.vqs.MCState(sampler, model_RBM, n_samples=300)\n",
    "\n",
    "# Apply function\n",
    "psi_apply_fun = vstate._apply_fun\n",
    "# Log function\n",
    "logpsi = vstate.log_value\n",
    "\n",
    "# Parameters\n",
    "parameters = vstate.parameters\n",
    "# parameters = jax.tree_util.tree_map(lambda x: x.real, parameters)\n",
    "\n",
    "parameters_concatenated, unconcatenate_function = nk.jax.tree_ravel(parameters)\n",
    "\n",
    "variables = vstate.variables\n",
    "\n",
    "# Get the samples\n",
    "samples = vstate.samples\n",
    "samples_2d = samples.reshape(-1, samples.shape[-1])\n",
    "\n",
    "def generate_hamiltonian(Delta): \n",
    "    # Initialization of the Hamiltonian\n",
    "    hamiltonian = nk.operator.LocalOperator(hi)\n",
    "    \n",
    "    # Add interaction terms with periodic boundary conditions\n",
    "    for i in range(L):\n",
    "        # Apply periodic boundary conditions\n",
    "        j = (i + 1) % L  # Wraps around to the first site when i = L-1\n",
    "    \n",
    "        # Add the S^z_i S^z_j term\n",
    "        hamiltonian = hamiltonian + nk.operator.spin.sigmaz(hi, i) @ nk.operator.spin.sigmaz(hi, j)\n",
    "    \n",
    "        # Add the Delta * (S^x_i S^x_j + S^y_i S^y_j) terms\n",
    "        hamiltonian = hamiltonian + Delta * (\n",
    "            nk.operator.spin.sigmax(hi, i) @ nk.operator.spin.sigmax(hi, j)\n",
    "            + nk.operator.spin.sigmay(hi, i) @ nk.operator.spin.sigmay(hi, j)\n",
    "        )\n",
    "    return hamiltonian\n",
    "\n",
    "delta = -1\n",
    "hamiltonian = generate_hamiltonian(delta)\n",
    "\n",
    "# Convert Hamiltonian to JAX operator\n",
    "hamiltonian_jax = hamiltonian.to_pauli_strings().to_jax_operator()\n",
    "\n",
    "def generate_hamiltonian_tfi(h_var):\n",
    "    # Initialization of the Hamiltonian\n",
    "    hamiltonian = nk.operator.LocalOperator(hi)\n",
    "    \n",
    "    # Add interaction terms with periodic boundary conditions\n",
    "    for i in range(L):\n",
    "        # Apply periodic boundary conditions\n",
    "        j = (i + 1) % L  # Wraps around to the first site when i = L-1\n",
    "    \n",
    "        # Add the S^z_i S^z_j term\n",
    "        hamiltonian = hamiltonian - nk.operator.spin.sigmaz(hi, i) @ nk.operator.spin.sigmaz(hi, j)\n",
    "    \n",
    "        # Add the Delta * (S^x_i S^x_j + S^y_i S^y_j) terms\n",
    "        hamiltonian = hamiltonian - h_var * nk.operator.spin.sigmax(hi, i)\n",
    "    return hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121695dd-a3e4-4b6d-bfe5-7fec0d4ef0f5",
   "metadata": {},
   "source": [
    "Let us compute $S$ and $\\vec{F}$ and $\\hat{\\mathcal{E}} = \\mathbb{E}_{\\hat{\\rho}}[E_L(\\sigma)] = \\mathbb{E}_{\\hat{\\rho}}[\\frac{\\hat{H} \\psi(\\sigma)}{\\psi(\\sigma)}] \\approx \\frac{1}{N_S} \\sum_{\\sigma | \\hat{H}_{\\sigma \\eta} \\neq 0} \\hat{H}_{\\sigma \\eta} \\frac{\\psi(\\eta)}{\\psi(\\sigma)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0041fc7c-9a4f-4640-86cc-79182130a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Jacobian function\n",
    "jacobian = nk.jax.jacobian(psi_apply_fun, parameters, samples_2d, mode='holomorphic', dense=True)\n",
    "\n",
    "############################################################################### Compute S\n",
    "\n",
    "def compute_S(jacobian_var, samples_2d_var):\n",
    "    O_mean = np.sum(jacobian_var, axis=0)/ samples_2d_var.shape[0]\n",
    "    delta_J = (jacobian_var - O_mean)\n",
    "\n",
    "    S = delta_J.conj().T@delta_J\n",
    "    S /= samples_2d_var.shape[0]\n",
    "\n",
    "    return S\n",
    "\n",
    "S = compute_S(jacobian, samples_2d) # Correct, compared to qgt = nk.optimizer.qgt.QGTJacobianDense(vstate).to_dense()\n",
    "\n",
    "############################################################################### Compute E_loc\n",
    "\n",
    "def compute_E_loc(vstate_log_value, hamiltonian_jax_var, samples_2d_var):\n",
    "    eta, H_sigmaeta = jax.vmap(hamiltonian_jax_var.get_conn_padded)(samples_2d_var)\n",
    "\n",
    "    logpsi_sigma = vstate_log_value(samples_2d_var) # A vector of applying logpsi to each sample in samples_2d\n",
    "    logpsi_eta = vstate.log_value(eta) # A vector of applying logpsi to each component of eta\n",
    "    \n",
    "    # Reshape log_sigma to match log_eta for broadcasting\n",
    "    log_sigma_expanded = logpsi_sigma[:, None]  # Shape: (304, 1)\n",
    "    \n",
    "    # Compute the exponentials\n",
    "    exp_values = jnp.exp(logpsi_eta - log_sigma_expanded)  # Now shape (304, 11)\n",
    "    \n",
    "    # Compute E_components as a sum over the weighted coefficients\n",
    "    E_loc = jnp.sum(H_sigmaeta * exp_values, axis=1)  # Final shape: (304,)\n",
    "\n",
    "    return E_loc\n",
    "\n",
    "E_loc = compute_E_loc(logpsi, hamiltonian_jax, samples_2d) # Correct, compared with E_loc_exact = vstate.local_estimators(hamiltonian_jax).reshape(304, )\n",
    "\n",
    "############################################################################### Compute F\n",
    "\n",
    "def compute_F(jacobian, E_loc):\n",
    "    O_mean = np.sum(jacobian, axis=0)/ samples_2d.shape[0]\n",
    "    delta_J = (jacobian - O_mean)\n",
    "    \n",
    "    F_w = delta_J.conj().T @ E_loc  # Ensure correct conjugate transpose multiplication\n",
    "    F = (F_w * 2)/(samples_2d.shape[0])\n",
    "    return F\n",
    "\n",
    "F = compute_F(jacobian, E_loc) # Correct,compared it to E_exact , F_exact = vstate.expect_and_grad(hamiltonian_jax)\n",
    "\n",
    "############################################################################### Compute mathcal_E\n",
    "\n",
    "def compute_mathcal_E(E_loc_var):\n",
    "    return jnp.mean(E_loc_var, 0)  # Final output as a scalar\n",
    "\n",
    "mathcal_E = compute_mathcal_E(E_loc) # Correct, compared it to E_exact , F_exact = vstate.expect_and_grad(hamiltonian_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6bd4f7-48ce-4589-91a2-ae32b3d4d1b6",
   "metadata": {},
   "source": [
    "Now, let us compute $\\mathbb{E}\\left[ \\frac{\\partial_{\\theta_i} \\psi(\\sigma)}{\\psi(\\sigma)} \\right] \\approx \\frac{1}{N_S} \\sum_{\\sigma} \\frac{\\partial \\log \\psi(\\sigma)}{\\partial \\theta_i}$. We will create a vector of size ($N_p$,) where the i-th component is exactly $\\mathbb{E}\\left[ \\frac{\\partial_{\\theta_i} \\psi(\\sigma)}{\\psi(\\sigma)} \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc137c4a-c12d-4766-98b4-0fbf39b35140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expectation_of_derivative(jacobian_var):\n",
    "     return jnp.mean(jacobian_var, axis=0)\n",
    "\n",
    "def compute_expectation_of_derivative_full_sum(jacobian_times_p_var):\n",
    "     return jnp.sum(jacobian_times_p_var, axis=0)\n",
    "\n",
    "exp_logpsi_vector = compute_expectation_of_derivative(jacobian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbdc0aa-58b3-4ee4-a4e4-724ae0333155",
   "metadata": {},
   "source": [
    "We move on to the next term. We first have to compute $E_{\\sigma, i} = \\sum_{\\sigma'} \\braket{\\sigma | H | \\sigma'} \\exp{(\\log{\\psi(\\sigma')} - \\log{\\psi(\\sigma)})} \\tilde{J}_{\\sigma', i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4d6197-b8c2-4c32-9edf-f32f4d2fa403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_E_sigma_i(psi_apply_fun_var, hamiltonian_jax_var, samples_2d_var, variables_var):\n",
    "    # Get connectivity and matrix elements for all samples\n",
    "    eta, H_sigmaeta = hamiltonian_jax_var.get_conn_padded(samples_2d_var)\n",
    "\n",
    "    num_samples, num_connections, n_sites = eta.shape\n",
    "\n",
    "    # Compute log values for eta and sigma\n",
    "    logpsi_eta = psi_apply_fun(variables_var, eta)  # Shape: (num_samples, num_connections)\n",
    "    logpsi_sigma = psi_apply_fun(variables_var, samples_2d_var)[:, None]  # Shape: (num_samples, 1)\n",
    "\n",
    "    # Compute exp(logpsi_eta - logpsi_sigma)\n",
    "    exp_term = jnp.exp(logpsi_eta - logpsi_sigma)  # Shape: (num_samples, num_connections)\n",
    "\n",
    "    tilde_jacobian = nk.jax.jacobian(psi_apply_fun_var, variables_var[\"params\"], eta.reshape(-1, n_sites), mode='holomorphic', dense=True).reshape(num_samples, num_connections, -1)\n",
    "    \n",
    "    # Compute E_sigma, i\n",
    "    E_sigma_i = jnp.sum(H_sigmaeta[:, :, None] * exp_term[:, :, None] * tilde_jacobian, axis=1)  # Shape: (num_samples, n_parameters)\n",
    "    \n",
    "    return E_sigma_i\n",
    "\n",
    "# Compute E_sigma_i\n",
    "E_sigma_i = compute_E_sigma_i(psi_apply_fun, hamiltonian_jax, samples_2d, variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd5478-f05f-4bee-90bd-fc08683cfb16",
   "metadata": {},
   "source": [
    "Now we compute $\\tilde{H} = \\frac{1}{N_S} \\sum_{\\sigma} \\Delta J_{\\sigma, i} E_{\\sigma, j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3318d5-59fa-4661-90fa-60575f095a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tilde_H(jacobian_var, E_sigma_i_var, samples_2d_var):\n",
    "    # Compute expectation value of the Jacobian\n",
    "    O_mean = jnp.mean(jacobian_var, axis=0)  # Shape: (num_parameters,)\n",
    "    \n",
    "    # Compute delta_J = (Jacobian - mean)\n",
    "    delta_J = jacobian_var - O_mean  # Shape: (num_samples, num_parameters)\n",
    "    \n",
    "    # Compute tilde_H using dot product\n",
    "    tilde_H = jnp.mean(delta_J[:,:, None]*E_sigma_i_var[:, None, :], axis = 0)\n",
    "\n",
    "    return tilde_H\n",
    "\n",
    "def compute_tilde_H_full_sum(jacobian_times_p_var, E_sigma_i_var, samples_2d_var):\n",
    "    # Compute expectation value of the Jacobian\n",
    "    O_mean = jnp.sum(jacobian_times_p_var, axis=0)  # Shape: (num_parameters,)\n",
    "    \n",
    "    # Compute delta_J = (Jacobian - mean)\n",
    "    delta_J = jacobian_times_p_var - O_mean  # Shape: (num_samples, num_parameters)\n",
    "    \n",
    "    # Compute tilde_H using dot product\n",
    "    tilde_H = jnp.sum(delta_J[:,:, None]*E_sigma_i_var[:, None, :], axis = 0)\n",
    "\n",
    "    return tilde_H\n",
    "\n",
    "# Compute H̃\n",
    "tilde_H = compute_tilde_H(jacobian, E_sigma_i, samples_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b40d3-3a66-4a81-ba0c-d3a2820b6a64",
   "metadata": {},
   "source": [
    "We now put everything together:\n",
    "$$\n",
    "H_{ij} = \\tilde{H}_{\\sigma, i} - \\vec{F}_i \\mathbb{E}_{\\hat{\\rho}}[\\nu_j(\\sigma)] - \\hat{\\mathcal{E}} \\hat{S}_{ij}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e06e4f7-1d09-42f1-aad1-d7ee73786409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_H_matrix(tilde_H_var, F_var, exp_logpsi_vector_var, mathcal_E_var, S_var):\n",
    "    tmp = tilde_H_var - mathcal_E_var * S_var\n",
    "    tmp -= F_var[:, None]*exp_logpsi_vector_var[None, :]\n",
    "    return tmp\n",
    "\n",
    "H_matrix = compute_H_matrix(tilde_H, F, exp_logpsi_vector, mathcal_E, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5f8b53-6623-454b-9254-7520893c125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b3696-67ac-46ab-9c6d-5e6a7192e5ab",
   "metadata": {},
   "source": [
    "# Optimization using the Rayleigh-Gauss-Newton preconditionner\n",
    "Let us now create a function that builds for us the preconditionner $P = \\eta(\\alpha H + (S + \\lambda I))$. We fix $\\eta$ snd the diag_shift to values that work well for SR. We then see the effect of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dde5901-91c6-4f74-92e2-8615f913a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_preconditionner(H_matrix_var, S_var, eta_var, alpha_var, diag_shift):\n",
    "    return (alpha_var*H_matrix_var + (S + diag_shift * jnp.eye(S_var.shape[0])))/eta_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ed70e-b8c3-417f-b3bc-e8ec7ffd1b28",
   "metadata": {},
   "source": [
    "We need to solve the following system:\n",
    "$$\n",
    "\\Delta \\vec{\\theta} = P^{-1} \\vec{F}\n",
    "$$\n",
    "\n",
    "where $\\Delta \\vec{\\theta}$ is the unkown vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22feb523-3196-4e1a-82b0-a86844f07f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = compute_preconditionner(H_matrix, S, 1, 0, 0)\n",
    "# delta_theta = np.linalg.solve(P, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d74b1af-3d91-45c0-9e67-91ef8c699497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.06178541796815\n"
     ]
    }
   ],
   "source": [
    "print(nk.exact.lanczos_ed(hamiltonian_jax)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13b752e-acde-4f0b-8c25-bcdece298f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.755156010020093"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathcal_E.item().real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511b3f7-1bd2-470e-b697-0afe7bea3620",
   "metadata": {},
   "source": [
    "# Comparison for different values of $\\epsilon$\n",
    "\n",
    "Let us now run the simulation for different values of epsilon and compare them to the SR optimization of NetKet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4089cc3c-c71c-44a7-a525-81079fa47594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters_var, delta_theta_var):\n",
    "    return parameters_var - delta_theta_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1818f0-fee5-49b2-bfc5-63e17492b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauriceconstantinmatar/uv-env/nk/.venv/lib/python3.12/site-packages/netket/vqs/mc/mc_state/state.py:276: UserWarning: n_samples=5000 (5000 per device/MPI rank) does not divide n_chains=16, increased to 5008 (5008 per device/MPI rank)\n",
      "  self.n_samples = n_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for alpha = 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████▎  | 374/400 [01:17<00:05,  5.01it/s]"
     ]
    }
   ],
   "source": [
    "delta_list = [5]\n",
    "\n",
    "eta = 5e-03\n",
    "alpha_list = [1/eta]\n",
    "diag_shift_1 = 1e-03\n",
    "\n",
    "lr_2 = 5e-02\n",
    "diag_shift_2 = 1e-03\n",
    "\n",
    "lr_3 = 5e-02\n",
    "\n",
    "iterations = 400\n",
    "sample_number_def = 5000\n",
    "\n",
    "\n",
    "for delta in delta_list:\n",
    "    hamiltonian = generate_hamiltonian(delta)\n",
    "    hamiltonian_jax = hamiltonian.to_pauli_strings().to_jax_operator()\n",
    "    \n",
    "    # Store energy histories for each epsilon\n",
    "    energy_histories = {}\n",
    "    \n",
    "    # Run for different epsilon values\n",
    "    for alpha in alpha_list:\n",
    "        print(f\"Running for alpha = {alpha}\")\n",
    "    \n",
    "        energy_history = []  # Reset before each run\n",
    "    \n",
    "        # Reinitialize the vstate before running the loop\n",
    "        vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))  # Ensure vstate is fresh\n",
    "        \n",
    "        # vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    \n",
    "        for i in tqdm(range(iterations)): \n",
    "            # Apply function\n",
    "            psi_apply_fun = vstate._apply_fun\n",
    "            logpsi = vstate.log_value\n",
    "    \n",
    "            # Parameters\n",
    "            parameters = vstate.parameters\n",
    "            # parameters = jax.tree_util.tree_map(lambda x: x.real, parameters)\n",
    "    \n",
    "            parameters_concatenated, unconcatenate_function = nk.jax.tree_ravel(parameters)\n",
    "\n",
    "            variables = vstate.variables\n",
    "    \n",
    "            # Get the samples\n",
    "            samples = vstate.samples\n",
    "            samples_2d = samples.reshape(-1, samples.shape[-1])\n",
    "\n",
    "            # samples_2d = hi.all_states()\n",
    "    \n",
    "            # Compute the Jacobian function\n",
    "            jacobian = nk.jax.jacobian(psi_apply_fun, parameters, samples_2d, mode='holomorphic', dense=True)\n",
    "    \n",
    "            # Compute various matrices\n",
    "            S = compute_S(jacobian, samples_2d)\n",
    "            E_loc = compute_E_loc(logpsi, hamiltonian_jax, samples_2d)\n",
    "            F = compute_F(jacobian, E_loc)\n",
    "            mathcal_E = compute_mathcal_E(E_loc)\n",
    "    \n",
    "            exp_logpsi_vector = compute_expectation_of_derivative(jacobian)\n",
    "            E_sigma_i = compute_E_sigma_i(psi_apply_fun, hamiltonian_jax, samples_2d, variables)\n",
    "            tilde_H = compute_tilde_H(jacobian, E_sigma_i, samples_2d)\n",
    "    \n",
    "            # Compute the preconditioner\n",
    "            P = compute_preconditionner(H_matrix, S, eta, alpha, diag_shift_1)\n",
    "\n",
    "            \"\"\"\n",
    "            # In case P is singular, continue otherwise\n",
    "            if np.linalg.cond(P) > 1e10:  # Condition number is too high (ill-conditioned matrix)\n",
    "                print(f\"Warning: Matrix P is nearly singular at alpha={alpha}, step={i}. Adjusting...\")\n",
    "                P = P + 1e-06  * np.eye(P.shape[0])  # Add regularization\n",
    "                alpha = 0\n",
    "            \"\"\"\n",
    "            \n",
    "            # Solve for parameter update\n",
    "            # delta_theta = np.linalg.solve(P, F)\n",
    "            # delta_theta, _, _, _ = lstsq(P, F)\n",
    "            delta_theta = np.linalg.pinv(P) @ F\n",
    "    \n",
    "            # Update parameters\n",
    "            new_pars = update_parameters(parameters_concatenated, delta_theta)\n",
    "            vstate.parameters = unconcatenate_function(new_pars)\n",
    "    \n",
    "            # Store energy value\n",
    "            energy_history.append(mathcal_E.item().real)\n",
    "    \n",
    "        # Store energy history for this epsilon\n",
    "        energy_histories[alpha] = energy_history\n",
    "        \n",
    "    #####################################################################################################\n",
    "    # Define folder and filename\n",
    "    folder_path = \"RGN_energy_log\"  # Change this to your preferred folder name\n",
    "    file_name = f\"energy_histories_delta={delta}_alpha={alpha}_diag_shift_1={diag_shift_1}_sampling=True.json\"\n",
    "    \n",
    "    # Create the folder if it doesn’t exist\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Full path to the JSON file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Save the dictionary as JSON\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(energy_histories, json_file, indent=4)\n",
    "    \n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    \n",
    "    #####################################################################################################\n",
    "\n",
    "    # Initialize VMC optimization with SGD and SR preconditioner\n",
    "    vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))\n",
    "    # vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    optimizer = nk.optimizer.Sgd(learning_rate=lr_2)\n",
    "    \n",
    "    gs = nk.driver.VMC(\n",
    "        hamiltonian, optimizer, variational_state=vstate, preconditioner=nk.optimizer.SR(diag_shift=diag_shift_2, holomorphic=True)\n",
    "    )\n",
    "    \n",
    "    # Construct the Json logger\n",
    "    log_file = f\"RGN_energy_log/NetKet_SR_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}_sampling=True.json\"\n",
    "    log = nk.logging.JsonLog(log_file)\n",
    "    \n",
    "    gs.run(n_iter=iterations, out=log)\n",
    "    #####################################################################################################\n",
    "    \n",
    "    # Initialize VMC optimization with SGD and SR preconditioner\n",
    "    vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))\n",
    "    # vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    optimizer = nk.optimizer.Sgd(learning_rate=lr_3)\n",
    "    \n",
    "    gs = nk.driver.VMC(\n",
    "        hamiltonian, optimizer, variational_state=vstate\n",
    "    )\n",
    "    \n",
    "    # Construct the Json logger\n",
    "    log_file = f\"RGN_energy_log/NetKet_GD_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}_sampling=True.json\"\n",
    "    log = nk.logging.JsonLog(log_file)\n",
    "    \n",
    "    gs.run(n_iter=iterations, out=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb754b80-66bf-4cc2-a772-2bbeb87f3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder and filenames\n",
    "folder_path = \"RGN_energy_log\"\n",
    "energy_file = f\"energy_histories_delta={delta}_alpha={alpha}_diag_shift_1={diag_shift_1}_sampling=True.json\"\n",
    "sr_file = f\"NetKet_SR_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}_sampling=True.json.log\"\n",
    "gd_file = f\"NetKet_GD_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}_sampling=True.json.log\"\n",
    "energy_path = os.path.join(folder_path, energy_file)\n",
    "sr_path = os.path.join(folder_path, sr_file)\n",
    "gd_path = os.path.join(folder_path, gd_file)\n",
    "\n",
    "# Load the energy history JSON file\n",
    "with open(energy_path, \"r\") as json_file:\n",
    "    energy_histories = json.load(json_file)\n",
    "\n",
    "# Load the SR optimization JSON file\n",
    "with open(sr_path, \"r\") as json_file:\n",
    "    sr_data = json.load(json_file)\n",
    "    sr_iters = sr_data[\"Energy\"][\"iters\"]\n",
    "    sr_energy = sr_data[\"Energy\"][\"Mean\"][\"real\"]\n",
    "\n",
    "# Load the GD optimization JSON file\n",
    "with open(gd_path, \"r\") as json_file:\n",
    "    gd_data = json.load(json_file)\n",
    "    gd_iters = gd_data[\"Energy\"][\"iters\"]    \n",
    "    gd_energy = gd_data[\"Energy\"][\"Mean\"][\"real\"]\n",
    "\n",
    "# Define a color map for different epsilon values\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(energy_histories)))\n",
    "\n",
    "# Compute the exact ground state energy\n",
    "exact_energy = nk.exact.lanczos_ed(hamiltonian_jax)[0]\n",
    "\n",
    "# Plot energy curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for (epsilon, energy_history), color in zip(energy_histories.items(), colors):\n",
    "    plt.plot(range(len(energy_history)), np.abs(np.array(energy_history)-exact_energy), label=f\"alpha = {alpha}\", color=color)\n",
    "\n",
    "# Plot SR optimization curve\n",
    "plt.plot(sr_iters, np.abs(np.array(sr_energy)-exact_energy), label=\"SR Optimization (NetKet)\", color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Plot SR optimization curve\n",
    "plt.plot(gd_iters, np.abs(np.array(gd_energy)-exact_energy), label=\"GD Optimization (NetKet)\", color=\"blue\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Iteration Steps\", fontsize=20)\n",
    "plt.ylabel(\"Energy\", fontsize=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(f\"Relative Error for Different Epsilon and NetKet SR (Delta = {delta}, alpha = {alpha}, eta = {eta}, lr_2 = {lr_2}, diag_shift_1 = {diag_shift_1}, diag_shift_2 = {diag_shift_2})\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# plt.xlim(0, 300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997ba8-8861-4aa7-b854-5d4d1eda9816",
   "metadata": {},
   "source": [
    "# Full summation\n",
    "\n",
    "Same as before, but we sum over all the elements of the Hilbert space. A subtelty we have to take care of is that we have now that:\n",
    "$$\n",
    "\\mathbb{E}[E_{\\text{loc}}(\\sigma)] = \\sum_{\\sigma} p(\\sigma) E_{\\text{loc}} = \\sum_{\\sigma} \\frac{|\\braket{\\sigma | \\psi}|^2}{\\braket{\\psi | \\psi}} E_{\\text{loc}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e7859-1bed-4583-adc4-9b3b25867303",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_list = [10]\n",
    "\n",
    "eta = 5e-03\n",
    "alpha_list = [eta]\n",
    "diag_shift_1 = 1e-06\n",
    "\n",
    "lr_2 = 5e-03\n",
    "diag_shift_2 = 1e-02\n",
    "\n",
    "lr_3 = 5e-03\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "for delta in delta_list:\n",
    "    hamiltonian = generate_hamiltonian(delta)\n",
    "    hamiltonian_jax = hamiltonian.to_pauli_strings().to_jax_operator()\n",
    "    \n",
    "    # Store energy histories for each epsilon\n",
    "    energy_histories = {}\n",
    "    \n",
    "    # Run for different epsilon values\n",
    "    for alpha in alpha_list:\n",
    "        print(f\"Running for alpha = {alpha}\")\n",
    "    \n",
    "        energy_history = []  # Reset before each run\n",
    "    \n",
    "        # Reinitialize the vstate before running the loop\n",
    "        # vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))  # Ensure vstate is fresh\n",
    "        \n",
    "        vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    \n",
    "        for i in tqdm(range(iterations)): \n",
    "            # Apply function\n",
    "            psi_apply_fun = vstate._apply_fun\n",
    "            logpsi = vstate.log_value\n",
    "    \n",
    "            # Parameters\n",
    "            parameters = vstate.parameters\n",
    "            # parameters = jax.tree_util.tree_map(lambda x: x.real, parameters)\n",
    "    \n",
    "            parameters_concatenated, unconcatenate_function = nk.jax.tree_ravel(parameters)\n",
    "\n",
    "            variables = vstate.variables\n",
    "    \n",
    "            # Get the samples\n",
    "            # samples = vstate.samples\n",
    "            # samples_2d = samples.reshape(-1, samples.shape[-1])\n",
    "\n",
    "            samples_2d = hi.all_states()\n",
    "    \n",
    "            # Compute the Jacobian function\n",
    "            jacobian = nk.jax.jacobian(psi_apply_fun, parameters, samples_2d, mode='holomorphic', dense=True)\n",
    "            p = vstate.probability_distribution().reshape(-1, 1)  # Shape becomes (1024, 1)\n",
    "            jacobian_times_p = p * jacobian  # Now shapes are (1024, 1) * (1024, 120)\n",
    "\n",
    "    \n",
    "            # Compute various matrices\n",
    "            S = nk.optimizer.qgt.QGTJacobianDense(vstate, holomorphic = True).to_dense()\n",
    "            E_loc = compute_E_loc(logpsi, hamiltonian_jax, samples_2d)\n",
    "            E_exact , F = vstate.expect_and_grad(hamiltonian_jax)\n",
    "            F, _ = nk.jax.tree_ravel(F)\n",
    "            mathcal_E = jnp.sum(vstate.probability_distribution()*E_loc)\n",
    "    \n",
    "            exp_logpsi_vector = compute_expectation_of_derivative_full_sum(jacobian_times_p)\n",
    "            E_sigma_i = compute_E_sigma_i(psi_apply_fun, hamiltonian_jax, samples_2d, variables)\n",
    "            tilde_H = compute_tilde_H_full_sum(jacobian_times_p, E_sigma_i, samples_2d)\n",
    "            H_matrix = compute_H_matrix(tilde_H, F, exp_logpsi_vector, mathcal_E, S)\n",
    "    \n",
    "            # Compute the preconditioner\n",
    "            P = compute_preconditionner(H_matrix, S, eta, alpha, diag_shift_1)\n",
    "    \n",
    "            delta_theta = np.linalg.pinv(P) @ F\n",
    "    \n",
    "            # Update parameters\n",
    "            new_pars = update_parameters(parameters_concatenated, delta_theta)\n",
    "            vstate.parameters = unconcatenate_function(new_pars)\n",
    "    \n",
    "            # Store energy value\n",
    "            energy_history.append(mathcal_E.item().real)\n",
    "    \n",
    "        # Store energy history for this epsilon\n",
    "        energy_histories[alpha] = energy_history\n",
    "\n",
    "    #####################################################################################################\n",
    "    # Define folder and filename\n",
    "    folder_path = \"RGN_energy_log\"  # Change this to your preferred folder name\n",
    "    file_name = f\"energy_histories_delta={delta}_alpha={alpha}_diag_shift_1={diag_shift_1}.json\"\n",
    "    \n",
    "    # Create the folder if it doesn’t exist\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Full path to the JSON file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Save the dictionary as JSON\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(energy_histories, json_file, indent=4)\n",
    "    \n",
    "    print(f\"Data saved to {file_path}\")\n",
    "\n",
    "    #####################################################################################################\n",
    "    # Initialize VMC optimization with SGD and SR preconditioner\n",
    "    # vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))\n",
    "    vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    optimizer = nk.optimizer.Sgd(learning_rate=lr_2)\n",
    "    \n",
    "    gs = nk.driver.VMC(\n",
    "        hamiltonian, optimizer, variational_state=vstate, preconditioner=nk.optimizer.SR(diag_shift=diag_shift_2, holomorphic=True)\n",
    "    )\n",
    "    \n",
    "    # Construct the Json logger\n",
    "    log_file = f\"RGN_energy_log/NetKet_SR_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}.json\"\n",
    "    log = nk.logging.JsonLog(log_file)\n",
    "    \n",
    "    gs.run(n_iter=iterations, out=log)\n",
    "    #####################################################################################################\n",
    "    \n",
    "    # Initialize VMC optimization with SGD and SR preconditioner\n",
    "    # vstate = nk.vqs.MCState(sampler, model_RBM, n_samples = sample_number_def, seed = jax.random.PRNGKey(0))\n",
    "    vstate = nk.vqs.FullSumState(hi, model_RBM, seed = jax.random.PRNGKey(0))\n",
    "    optimizer = nk.optimizer.Sgd(learning_rate=lr_3)\n",
    "    \n",
    "    gs = nk.driver.VMC(\n",
    "        hamiltonian, optimizer, variational_state=vstate\n",
    "    )\n",
    "    \n",
    "    # Construct the Json logger\n",
    "    log_file = f\"RGN_energy_log/NetKet_GD_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}.json\"\n",
    "    log = nk.logging.JsonLog(log_file)\n",
    "    \n",
    "    gs.run(n_iter=iterations, out=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d714bcd-a966-4fdd-a9fd-b53f1fcea893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder and filenames\n",
    "folder_path = \"RGN_energy_log\"\n",
    "energy_file = f\"energy_histories_delta={delta}_alpha={alpha}_diag_shift_1={diag_shift_1}.json\"\n",
    "sr_file = f\"NetKet_SR_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}.json.log\"\n",
    "gd_file = f\"NetKet_GD_log_delta={delta}_lr_2={lr_2}_diag_shift_2={diag_shift_2}.json.log\"\n",
    "energy_path = os.path.join(folder_path, energy_file)\n",
    "sr_path = os.path.join(folder_path, sr_file)\n",
    "gd_path = os.path.join(folder_path, gd_file)\n",
    "\n",
    "# Load the energy history JSON file\n",
    "with open(energy_path, \"r\") as json_file:\n",
    "    energy_histories = json.load(json_file)\n",
    "\n",
    "# Load the SR optimization JSON file\n",
    "with open(sr_path, \"r\") as json_file:\n",
    "    sr_data = json.load(json_file)\n",
    "    sr_iters = sr_data[\"Energy\"][\"iters\"]\n",
    "    sr_energy = sr_data[\"Energy\"][\"Mean\"][\"real\"]\n",
    "\n",
    "# Load the GD optimization JSON file\n",
    "with open(gd_path, \"r\") as json_file:\n",
    "    gd_data = json.load(json_file)\n",
    "    gd_iters = gd_data[\"Energy\"][\"iters\"]\n",
    "    gd_energy = gd_data[\"Energy\"][\"Mean\"][\"real\"]\n",
    "\n",
    "# Define a color map for different epsilon values\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(energy_histories)))\n",
    "\n",
    "# Compute the exact ground state energy\n",
    "exact_energy = nk.exact.lanczos_ed(hamiltonian_jax)[0]\n",
    "\n",
    "# Plot energy curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for (epsilon, energy_history), color in zip(energy_histories.items(), colors):\n",
    "    plt.plot(range(len(energy_history)), np.abs(np.array(energy_history)-exact_energy), label=f\"RGN\", color=color)\n",
    "\n",
    "# Plot SR optimization cu\n",
    "plt.plot(sr_iters, np.abs(np.array(sr_energy)-exact_energy), label=\"SR Optimization (NetKet)\", color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Plot SR optimization curve\n",
    "plt.plot(gd_iters, np.abs(np.array(gd_energy)-exact_energy), label=\"GD Optimization (NetKet)\", color=\"blue\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Iteration Steps\", fontsize=20)\n",
    "plt.ylabel(\"Relative Error\", fontsize=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(f\"Plot of the Relative Error for different optimization techniques (Full Sum), Delta={delta}\", fontsize=13)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
